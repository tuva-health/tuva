name: tuva_internal_dbt_v1.9.4
on:
  pull_request:
    branches:
      - main
      - 'minor-release*'
      - 'release*'
  workflow_dispatch:

concurrency:
  group: ci-testing
  cancel-in-progress: false

env:
  PYTHON_VERSION: '3.11'
  LINT_SCRIPT_PATH: ./lint_tuva_project.sh

permissions:
  contents: read
  pull-requests: write

jobs:
  # ============================================================================
  # Linting Job
  # ============================================================================
  sqlfluff-lint:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-snowflake==1.9.4 sqlfluff==3.3.1 sqlfluff-templater-dbt

      - name: Create dbt profiles directory
        run: mkdir -p ~/.dbt

      - name: Create dbt profiles.yml for linting
        run: |
          echo "default:
            outputs:
              dev:
                account: \"{{ env_var('DBT_TUVA_SNOWFLAKE_ACCOUNT') }}\"
                database: dev_ci_testing
                password: \"{{ env_var('DBT_SNOWFLAKE_CI_PASSWORD') }}\"
                role: \"{{ env_var('DBT_SNOWFLAKE_CI_ROLE') }}\"
                schema: \"{{ env_var('DBT_SNOWFLAKE_CI_SCHEMA') }}\"
                threads: 8
                type: snowflake
                user: \"{{ env_var('DBT_SNOWFLAKE_CI_USER') }}\"
                warehouse: \"{{ env_var('DBT_SNOWFLAKE_CI_WAREHOUSE') }}\"
            target: dev" > ~/.dbt/profiles.yml

      - name: Check if lint script exists
        run: |
          if [ ! -f "${{ env.LINT_SCRIPT_PATH }}" ]; then
            echo "Error: Lint script not found at ${{ env.LINT_SCRIPT_PATH }}"
            exit 1
          fi

      - name: Make lint script executable
        run: chmod +x ${{ env.LINT_SCRIPT_PATH }}

      - name: Run SQLFluff Lint Check
        id: lint_script
        run: bash ${{ env.LINT_SCRIPT_PATH }} --ci

      - name: Read Lint Output File on Failure
        id: read-lint-output
        if: failure() && steps.lint_script.outcome == 'failure'
        run: |
          output_file="SQLFLUFF_LINTER_OUTPUT.TXT"
          if [ -f "$output_file" ]; then
            content=$(cat "$output_file")
          else
            content="Lint output file not found."
          fi
          content="${content//'%'/'%25'}"
          EOF_MARKER=$(uuidgen)
          echo "content<<${EOF_MARKER}" >> $GITHUB_OUTPUT
          echo "$content" >> $GITHUB_OUTPUT
          echo "${EOF_MARKER}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Create Comment on PR Failure
        if: failure() && steps.lint_script.outcome == 'failure' && github.event_name == 'pull_request'
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          token: ${{ secrets.GITHUB_TOKEN }}
          body: |
            âŒ **SQLFluff Linting Failed**

            Issues were found that require manual correction.
            Please review the output below, fix the issues locally, and commit the changes.

            ```text
            ${{ steps.read-lint-output.outputs.content }}
            ```

  # ============================================================================
  # BigQuery
  # ============================================================================
  bigquery_clinical_and_claims_enabled:
    needs: sqlfluff-lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt and BigQuery adapter
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-bigquery==1.9.4

      - name: Setup BigQuery credentials
        run: |
          echo "${{ secrets.TUVA_BIGQUERY_TOKEN }}" | base64 --decode > ./creds.json
        working-directory: ci_testing

      - name: Create dbt profile
        env:
          SCHEMA_SUFFIX: ${{ github.run_id }}
        run: |
          mkdir -p ./profiles/bigquery
          python3 << 'EOF'
          import os
          import yaml
          
          profile = {
              'default': {
                  'outputs': {
                      'dev': {
                          'type': 'bigquery',
                          'method': 'service-account',
                          'project': 'dev-ci-testing',
                          'keyfile': './creds.json',
                          'dataset': f"ci_test_{os.environ['SCHEMA_SUFFIX']}",
                          'threads': 8,
                          'timeout_seconds': 300,
                          'priority': 'interactive'
                      }
                  },
                  'target': 'dev'
              }
          }
          
          with open('./profiles/bigquery/profiles.yml', 'w') as f:
              yaml.dump(profile, f, default_flow_style=False)
          EOF
        working-directory: ci_testing

      - name: dbt deps
        run: dbt deps --profiles-dir ./profiles/bigquery
        working-directory: ci_testing

      - name: dbt debug
        run: dbt debug --profiles-dir ./profiles/bigquery
        working-directory: ci_testing

      - name: dbt build
        run: |
          dbt build --full-refresh --profiles-dir ./profiles/bigquery \
            --vars '{"use_synthetic_data": true,"clinical_enabled": true,"claims_enabled": true,"provider_attribution_enabled":true,"fhir_preprocessing_enabled":true}'
        working-directory: ci_testing

  # ============================================================================
  # Fabric
  # ============================================================================
  fabric_clinical_and_claims_enabled:
    needs: sqlfluff-lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install ODBC Driver 18 for SQL Server
        run: |
          curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -
          curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/msprod.list
          sudo apt-get update
          sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18

      - name: Install dbt and Fabric adapter
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-fabric==1.9.4

      - name: Create dbt profile
        env:
          FABRIC_HOST: ${{ secrets.DBT_FABRIC_CI_HOST }}
          FABRIC_SP_ID: ${{ secrets.DBT_FABRIC_SERVICE_PRINCIPAL_ID }}
          FABRIC_SP_SECRET: ${{ secrets.DBT_FABRIC_SERVICE_PRINCIPAL_SECRET }}
          FABRIC_TENANT: ${{ secrets.DBT_FABRIC_TENANT_ID }}
          FABRIC_DATABASE: ${{ secrets.DBT_FABRIC_CI_DATABASE }}
          FABRIC_SCHEMA: ${{ secrets.DBT_FABRIC_CI_SCHEMA }}
        run: |
          mkdir -p ./profiles/fabric
          python3 << 'EOF'
          import os
          import yaml
          
          profile = {
              'default': {
                  'outputs': {
                      'dev': {
                          'type': 'fabric',
                          'driver': 'ODBC Driver 18 for SQL Server',
                          'server': os.environ['FABRIC_HOST'],
                          'port': 1433,
                          'database': os.environ['FABRIC_DATABASE'],
                          'schema': os.environ['FABRIC_SCHEMA'],
                          'authentication': 'serviceprincipal',
                          'tenant_id': os.environ['FABRIC_TENANT'],
                          'client_id': os.environ['FABRIC_SP_ID'],
                          'client_secret': os.environ['FABRIC_SP_SECRET'],
                          'threads': 4,
                          'trust_cert': False,
                          'encrypt': True
                      }
                  },
                  'target': 'dev'
              }
          }
          
          with open('./profiles/fabric/profiles.yml', 'w') as f:
              yaml.dump(profile, f, default_flow_style=False)
          EOF
        working-directory: ci_testing

      - name: dbt deps
        run: dbt deps --profiles-dir ./profiles/fabric
        working-directory: ci_testing

      - name: dbt debug
        run: dbt debug --profiles-dir ./profiles/fabric
        working-directory: ci_testing

      - name: dbt build
        run: |
          dbt build --full-refresh --profiles-dir ./profiles/fabric \
            --vars '{"use_synthetic_data": true,"clinical_enabled":true,"claims_enabled":true,"provider_attribution_enabled":true,"fhir_preprocessing_enabled":true}'
        working-directory: ci_testing

  # ============================================================================
  # Redshift Serverless
  # ============================================================================
  redshift_clinical_and_claims_enabled:
    needs: sqlfluff-lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt and Redshift adapter
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-redshift==1.9.4

      - name: Create dbt profile
        env:
          REDSHIFT_HOST: ${{ secrets.REDSHIFT_SERVERLESS_TEST_HOST }}
          REDSHIFT_USER: ${{ secrets.REDSHIFT_SERVERLESS_TEST_USERNAME }}
          REDSHIFT_PASSWORD: ${{ secrets.REDSHIFT_SERVERLESS_TEST_PASSWORD }}
          REDSHIFT_DATABASE: ${{ secrets.REDSHIFT_SERVERLESS_TEST_DATABASE }}
          SCHEMA_SUFFIX: ${{ github.run_id }}
        run: |
          mkdir -p ./profiles/redshift
          python3 << 'EOF'
          import os
          import yaml
          
          profile = {
              'default': {
                  'outputs': {
                      'dev': {
                          'type': 'redshift',
                          'host': os.environ['REDSHIFT_HOST'],
                          'port': 5439,
                          'user': os.environ['REDSHIFT_USER'],
                          'password': os.environ['REDSHIFT_PASSWORD'],
                          'dbname': os.environ['REDSHIFT_DATABASE'],
                          'schema': f"ci_test_{os.environ['SCHEMA_SUFFIX']}",
                          'threads': 32,
                          'sslmode': 'require',
                          'is_serverless': True,
                          'connect_timeout': 120
                      }
                  },
                  'target': 'dev'
              }
          }
          
          with open('./profiles/redshift/profiles.yml', 'w') as f:
              yaml.dump(profile, f, default_flow_style=False)
          EOF
        working-directory: ci_testing

      - name: dbt deps
        run: dbt deps --profiles-dir ./profiles/redshift
        working-directory: ci_testing

      - name: dbt debug
        run: dbt debug --profiles-dir ./profiles/redshift
        working-directory: ci_testing

      - name: dbt build
        run: |
          dbt build --full-refresh --profiles-dir ./profiles/redshift \
            --vars '{"use_synthetic_data": true,"clinical_enabled": true,"claims_enabled": true,"provider_attribution_enabled":true,"fhir_preprocessing_enabled":true}'
        working-directory: ci_testing

  # ============================================================================
  # Snowflake - Main Test
  # ============================================================================
  snowflake_clinical_and_claims_enabled:
    needs: sqlfluff-lint
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt and Snowflake adapter
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-snowflake==1.9.4

      - name: Create dbt profile
        env:
          SF_ACCOUNT: ${{ secrets.DBT_TUVA_SNOWFLAKE_ACCOUNT }}
          SF_USER: ${{ secrets.DBT_SNOWFLAKE_CI_USER }}
          SF_PASSWORD: ${{ secrets.DBT_SNOWFLAKE_CI_PASSWORD }}
          SF_DATABASE: ${{ secrets.DBT_TUVA_CI_DATABASE }}
          SF_ROLE: ${{ secrets.DBT_SNOWFLAKE_CI_ROLE }}
          SF_WAREHOUSE: ${{ secrets.DBT_SNOWFLAKE_CI_WAREHOUSE }}
          SF_SCHEMA: ${{ secrets.DBT_SNOWFLAKE_CI_SCHEMA }}
        run: |
          mkdir -p ./profiles/snowflake
          python3 << 'EOF'
          import os
          import yaml
          
          profile = {
              'default': {
                  'outputs': {
                      'dev': {
                          'type': 'snowflake',
                          'account': os.environ['SF_ACCOUNT'],
                          'user': os.environ['SF_USER'],
                          'password': os.environ['SF_PASSWORD'],
                          'database': os.environ['SF_DATABASE'],
                          'schema': os.environ['SF_SCHEMA'],
                          'warehouse': os.environ['SF_WAREHOUSE'],
                          'role': os.environ['SF_ROLE'],
                          'threads': 8
                      }
                  },
                  'target': 'dev'
              }
          }
          
          with open('./profiles/snowflake/profiles.yml', 'w') as f:
              yaml.dump(profile, f, default_flow_style=False)
          EOF
        working-directory: ci_testing

      - name: dbt deps
        run: dbt deps --profiles-dir ./profiles/snowflake
        working-directory: ci_testing

      - name: dbt debug
        run: dbt debug --profiles-dir ./profiles/snowflake
        working-directory: ci_testing

      - name: dbt build
        run: |
          dbt build --full-refresh --profiles-dir ./profiles/snowflake \
            --vars '{"use_synthetic_data": true,"clinical_enabled":true,"claims_enabled":true,"fhir_preprocessing_enabled":true}'
        working-directory: ci_testing

  # ============================================================================
  # Snowflake - Additional Tests (Compile Only for Speed)
  # ============================================================================
  snowflake_variant_tests:
    needs: snowflake_clinical_and_claims_enabled
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test_config:
          - name: "claims_only"
            vars: '{"use_synthetic_data": true,"claims_enabled":true}'
          - name: "claims_with_provider_attribution"
            vars: '{"use_synthetic_data": true,"claims_enabled":true,"provider_attribution_enabled":true}'
          - name: "clinical_only"
            vars: '{"use_synthetic_data": true,"clinical_enabled":true}'
          - name: "provider_attribution_only"
            vars: '{"use_synthetic_data": true,"provider_attribution_enabled":true}'
          - name: "semantic_layer"
            vars: '{"use_synthetic_data": true,"claims_enabled":true,"semantic_layer_enabled":true}'

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dbt and Snowflake adapter
        run: |
          python -m pip install --upgrade pip
          pip install dbt-core==1.9.4 dbt-snowflake==1.9.4

      - name: Create dbt profile
        env:
          SF_ACCOUNT: ${{ secrets.DBT_TUVA_SNOWFLAKE_ACCOUNT }}
          SF_USER: ${{ secrets.DBT_SNOWFLAKE_CI_USER }}
          SF_PASSWORD: ${{ secrets.DBT_SNOWFLAKE_CI_PASSWORD }}
          SF_DATABASE: ${{ secrets.DBT_TUVA_CI_DATABASE }}
          SF_ROLE: ${{ secrets.DBT_SNOWFLAKE_CI_ROLE }}
          SF_WAREHOUSE: ${{ secrets.DBT_SNOWFLAKE_CI_WAREHOUSE }}
          SF_SCHEMA: ${{ secrets.DBT_SNOWFLAKE_CI_SCHEMA }}
        run: |
          mkdir -p ./profiles/snowflake
          python3 << 'EOF'
          import os
          import yaml
          
          profile = {
              'default': {
                  'outputs': {
                      'dev': {
                          'type': 'snowflake',
                          'account': os.environ['SF_ACCOUNT'],
                          'user': os.environ['SF_USER'],
                          'password': os.environ['SF_PASSWORD'],
                          'database': os.environ['SF_DATABASE'],
                          'schema': os.environ['SF_SCHEMA'],
                          'warehouse': os.environ['SF_WAREHOUSE'],
                          'role': os.environ['SF_ROLE'],
                          'threads': 8
                      }
                  },
                  'target': 'dev'
              }
          }
          
          with open('./profiles/snowflake/profiles.yml', 'w') as f:
              yaml.dump(profile, f, default_flow_style=False)
          EOF
        working-directory: ci_testing

      - name: dbt deps
        run: dbt deps --profiles-dir ./profiles/snowflake
        working-directory: ci_testing

      - name: dbt compile - ${{ matrix.test_config.name }}
        run: |
          dbt compile --profiles-dir ./profiles/snowflake --vars '${{ matrix.test_config.vars }}'
        working-directory: ci_testing
